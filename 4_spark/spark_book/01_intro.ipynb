{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Spark Introduction`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ```spark sql```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import types,SparkSession\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "23/04/19 18:42:31 WARN Utils: Your hostname, MSI resolves to a loopback address: 127.0.1.1; using 172.25.166.20 instead (on interface eth0)\n",
      "23/04/19 18:42:31 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/04/19 18:42:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "jardrv = \"/home/snehil/Downloads/postgresql-42.6.0.jar\"\n",
    "\n",
    "spark = SparkSession.builder.config('spark.driver.extraClassPath', jardrv).getOrCreate()\n",
    "url = 'jdbc:postgresql://127.0.0.1/general'\n",
    "properties = {'user': 'root', 'password': 'root'}\n",
    "df = spark.read.jdbc(url=url, table='reddit_data.hot_posts', properties=properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('reddit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_score = spark.sql(\"\"\"\n",
    "\n",
    "    select subreddit,count(*) as count ,avg(score) avg_score from reddit group by subreddit order by count desc;\n",
    "    \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+------------------+\n",
      "|       subreddit|count|         avg_score|\n",
      "+----------------+-----+------------------+\n",
      "|      reddit.com| 9151|269.99562889301717|\n",
      "|    pcmasterrace| 7269| 9541.178428944835|\n",
      "|           penis| 6740| 152.3952522255193|\n",
      "|     houseplants| 6370|1731.0708006279435|\n",
      "|           boobs| 6365| 731.9198743126473|\n",
      "|           DotA2| 6229|1481.2438593674747|\n",
      "|          Tinder| 6222|10118.672774027644|\n",
      "|       AskReddit| 6115|13158.353393295176|\n",
      "|          gaming| 5997|24030.774387193596|\n",
      "|VirtualYoutubers| 5936| 458.0025269541779|\n",
      "|         ireland| 5914|1208.9589110585052|\n",
      "|           funny| 5890|29731.660611205432|\n",
      "| HomeImprovement| 5815|247.11074806534825|\n",
      "|        antiwork| 5752|13970.382127955494|\n",
      "|          comics| 5752| 9868.485396383867|\n",
      "|        painting| 5664| 623.5607344632768|\n",
      "|        Sexsells| 5600|107.75660714285715|\n",
      "|        totalwar| 5575|1211.1991031390135|\n",
      "|           meirl| 5573|16520.258388659608|\n",
      "|          movies| 5532|12654.437816341288|\n",
      "+----------------+-----+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_score.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ```spark mllib```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = types.StructType([\n",
    "    types.StructField('CRIM', types.DoubleType(), True), \n",
    "    types.StructField('ZN', types.DoubleType(), True), \n",
    "    types.StructField('INDUS', types.DoubleType(), True), \n",
    "    types.StructField('CHAS', types.DoubleType(), True), \n",
    "    types.StructField('NOX', types.DoubleType(), True), \n",
    "    types.StructField('RM', types.DoubleType(), True), \n",
    "    types.StructField('AGE', types.DoubleType(), True), \n",
    "    types.StructField('DIS', types.DoubleType(), True), \n",
    "    types.StructField('RAD', types.DoubleType(), True), \n",
    "    types.StructField('TAX', types.DoubleType(), True), \n",
    "    types.StructField('PT', types.DoubleType(), True), \n",
    "    types.StructField('B', types.DoubleType(), True), \n",
    "    types.StructField('LSTAT', types.DoubleType(), True), \n",
    "    types.StructField('MV', types.DoubleType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df = spark.read.csv('/home/snehil/snehi/Desktop/Data/housing.csv',inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PT', 'B', 'LSTAT','MV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df = housing_df.rdd.map(lambda x:re.sub(r'\\s+',' ',x[0].strip()).split()).map(lambda x:[float(i) for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df = housing_df.toDF(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----+----+-----+-----+-----+------+---+-----+----+------+-----+----+\n",
      "|   CRIM|  ZN|INDUS|CHAS|  NOX|   RM|  AGE|   DIS|RAD|  TAX|  PT|     B|LSTAT|  MV|\n",
      "+-------+----+-----+----+-----+-----+-----+------+---+-----+----+------+-----+----+\n",
      "|0.00632|18.0| 2.31| 0.0|0.538|6.575| 65.2|  4.09|1.0|296.0|15.3| 396.9| 4.98|24.0|\n",
      "|0.02731| 0.0| 7.07| 0.0|0.469|6.421| 78.9|4.9671|2.0|242.0|17.8| 396.9| 9.14|21.6|\n",
      "|0.02729| 0.0| 7.07| 0.0|0.469|7.185| 61.1|4.9671|2.0|242.0|17.8|392.83| 4.03|34.7|\n",
      "|0.03237| 0.0| 2.18| 0.0|0.458|6.998| 45.8|6.0622|3.0|222.0|18.7|394.63| 2.94|33.4|\n",
      "|0.06905| 0.0| 2.18| 0.0|0.458|7.147| 54.2|6.0622|3.0|222.0|18.7| 396.9| 5.33|36.2|\n",
      "|0.02985| 0.0| 2.18| 0.0|0.458| 6.43| 58.7|6.0622|3.0|222.0|18.7|394.12| 5.21|28.7|\n",
      "|0.08829|12.5| 7.87| 0.0|0.524|6.012| 66.6|5.5605|5.0|311.0|15.2| 395.6|12.43|22.9|\n",
      "|0.14455|12.5| 7.87| 0.0|0.524|6.172| 96.1|5.9505|5.0|311.0|15.2| 396.9|19.15|27.1|\n",
      "|0.21124|12.5| 7.87| 0.0|0.524|5.631|100.0|6.0821|5.0|311.0|15.2|386.63|29.93|16.5|\n",
      "|0.17004|12.5| 7.87| 0.0|0.524|6.004| 85.9|6.5921|5.0|311.0|15.2|386.71| 17.1|18.9|\n",
      "|0.22489|12.5| 7.87| 0.0|0.524|6.377| 94.3|6.3467|5.0|311.0|15.2|392.52|20.45|15.0|\n",
      "|0.11747|12.5| 7.87| 0.0|0.524|6.009| 82.9|6.2267|5.0|311.0|15.2| 396.9|13.27|18.9|\n",
      "|0.09378|12.5| 7.87| 0.0|0.524|5.889| 39.0|5.4509|5.0|311.0|15.2| 390.5|15.71|21.7|\n",
      "|0.62976| 0.0| 8.14| 0.0|0.538|5.949| 61.8|4.7075|4.0|307.0|21.0| 396.9| 8.26|20.4|\n",
      "|0.63796| 0.0| 8.14| 0.0|0.538|6.096| 84.5|4.4619|4.0|307.0|21.0|380.02|10.26|18.2|\n",
      "|0.62739| 0.0| 8.14| 0.0|0.538|5.834| 56.5|4.4986|4.0|307.0|21.0|395.62| 8.47|19.9|\n",
      "|1.05393| 0.0| 8.14| 0.0|0.538|5.935| 29.3|4.4986|4.0|307.0|21.0|386.85| 6.58|23.1|\n",
      "| 0.7842| 0.0| 8.14| 0.0|0.538| 5.99| 81.7|4.2579|4.0|307.0|21.0|386.75|14.67|17.5|\n",
      "|0.80271| 0.0| 8.14| 0.0|0.538|5.456| 36.6|3.7965|4.0|307.0|21.0|288.99|11.69|20.2|\n",
      "| 0.7258| 0.0| 8.14| 0.0|0.538|5.727| 69.5|3.7965|4.0|307.0|21.0|390.95|11.28|18.2|\n",
      "+-------+----+-----+----+-----+-----+-----+------+---+-----+----+------+-----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "housing_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df = housing_df\\\n",
    "             .withColumn('CHAS',housing_df.CHAS.cast('int'))\\\n",
    "             .withColumn('RAD',housing_df.RAD.cast('int'))\\\n",
    "             .withColumn('TAX',housing_df.TAX.cast('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CRIM: double (nullable = true)\n",
      " |-- ZN: double (nullable = true)\n",
      " |-- INDUS: double (nullable = true)\n",
      " |-- CHAS: integer (nullable = true)\n",
      " |-- NOX: double (nullable = true)\n",
      " |-- RM: double (nullable = true)\n",
      " |-- AGE: double (nullable = true)\n",
      " |-- DIS: double (nullable = true)\n",
      " |-- RAD: integer (nullable = true)\n",
      " |-- TAX: integer (nullable = true)\n",
      " |-- PT: double (nullable = true)\n",
      " |-- B: double (nullable = true)\n",
      " |-- LSTAT: double (nullable = true)\n",
      " |-- MV: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "housing_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/04/18 18:25:55 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+------------------+-------------------+------------------+------------------+-----------------+-----------------+------------------+------------------+------------------+------------------+------------------+\n",
      "|summary|              CRIM|                ZN|             INDUS|              CHAS|                NOX|                RM|               AGE|              DIS|              RAD|               TAX|                PT|                 B|             LSTAT|                MV|\n",
      "+-------+------------------+------------------+------------------+------------------+-------------------+------------------+------------------+-----------------+-----------------+------------------+------------------+------------------+------------------+------------------+\n",
      "|  count|               506|               506|               506|               506|                506|               506|               506|              506|              506|               506|               506|               506|               506|               506|\n",
      "|   mean|3.6135235573122535|11.363636363636363|11.136778656126504|0.0691699604743083| 0.5546950592885372| 6.284634387351787| 68.57490118577078|3.795042687747034|9.549407114624506| 408.2371541501976|18.455533596837967|356.67403162055257|12.653063241106723|22.532806324110698|\n",
      "| stddev| 8.601545105332491| 23.32245299451514| 6.860352940897589|0.2539940413404101|0.11587767566755584|0.7026171434153232|28.148861406903595| 2.10571012662761|8.707259384239366|168.53711605495903|2.1649455237144455| 91.29486438415782| 7.141061511348571| 9.197104087379815|\n",
      "|    min|           0.00632|               0.0|              0.46|                 0|              0.385|             3.561|               2.9|           1.1296|                1|               187|              12.6|              0.32|              1.73|               5.0|\n",
      "|    max|           88.9762|             100.0|             27.74|                 1|              0.871|              8.78|             100.0|          12.1265|               24|               711|              22.0|             396.9|             37.97|              50.0|\n",
      "+-------+------------------+------------------+------------------+------------------+-------------------+------------------+------------------+-----------------+-----------------+------------------+------------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "housing_df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>summary</th>\n",
       "      <td>count</td>\n",
       "      <td>mean</td>\n",
       "      <td>stddev</td>\n",
       "      <td>min</td>\n",
       "      <td>max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRIM</th>\n",
       "      <td>506</td>\n",
       "      <td>3.6135235573122535</td>\n",
       "      <td>8.601545105332491</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>88.9762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZN</th>\n",
       "      <td>506</td>\n",
       "      <td>11.363636363636363</td>\n",
       "      <td>23.32245299451514</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDUS</th>\n",
       "      <td>506</td>\n",
       "      <td>11.136778656126504</td>\n",
       "      <td>6.860352940897589</td>\n",
       "      <td>0.46</td>\n",
       "      <td>27.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHAS</th>\n",
       "      <td>506</td>\n",
       "      <td>0.0691699604743083</td>\n",
       "      <td>0.2539940413404101</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOX</th>\n",
       "      <td>506</td>\n",
       "      <td>0.5546950592885372</td>\n",
       "      <td>0.11587767566755584</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RM</th>\n",
       "      <td>506</td>\n",
       "      <td>6.284634387351787</td>\n",
       "      <td>0.7026171434153232</td>\n",
       "      <td>3.561</td>\n",
       "      <td>8.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE</th>\n",
       "      <td>506</td>\n",
       "      <td>68.57490118577078</td>\n",
       "      <td>28.148861406903595</td>\n",
       "      <td>2.9</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIS</th>\n",
       "      <td>506</td>\n",
       "      <td>3.795042687747034</td>\n",
       "      <td>2.10571012662761</td>\n",
       "      <td>1.1296</td>\n",
       "      <td>12.1265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAD</th>\n",
       "      <td>506</td>\n",
       "      <td>9.549407114624506</td>\n",
       "      <td>8.707259384239366</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAX</th>\n",
       "      <td>506</td>\n",
       "      <td>408.2371541501976</td>\n",
       "      <td>168.53711605495903</td>\n",
       "      <td>187</td>\n",
       "      <td>711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PT</th>\n",
       "      <td>506</td>\n",
       "      <td>18.455533596837967</td>\n",
       "      <td>2.1649455237144455</td>\n",
       "      <td>12.6</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>506</td>\n",
       "      <td>356.67403162055257</td>\n",
       "      <td>91.29486438415782</td>\n",
       "      <td>0.32</td>\n",
       "      <td>396.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTAT</th>\n",
       "      <td>506</td>\n",
       "      <td>12.653063241106723</td>\n",
       "      <td>7.141061511348571</td>\n",
       "      <td>1.73</td>\n",
       "      <td>37.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MV</th>\n",
       "      <td>506</td>\n",
       "      <td>22.532806324110698</td>\n",
       "      <td>9.197104087379815</td>\n",
       "      <td>5.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0                   1                    2        3        4\n",
       "summary  count                mean               stddev      min      max\n",
       "CRIM       506  3.6135235573122535    8.601545105332491  0.00632  88.9762\n",
       "ZN         506  11.363636363636363    23.32245299451514      0.0    100.0\n",
       "INDUS      506  11.136778656126504    6.860352940897589     0.46    27.74\n",
       "CHAS       506  0.0691699604743083   0.2539940413404101        0        1\n",
       "NOX        506  0.5546950592885372  0.11587767566755584    0.385    0.871\n",
       "RM         506   6.284634387351787   0.7026171434153232    3.561     8.78\n",
       "AGE        506   68.57490118577078   28.148861406903595      2.9    100.0\n",
       "DIS        506   3.795042687747034     2.10571012662761   1.1296  12.1265\n",
       "RAD        506   9.549407114624506    8.707259384239366        1       24\n",
       "TAX        506   408.2371541501976   168.53711605495903      187      711\n",
       "PT         506  18.455533596837967   2.1649455237144455     12.6     22.0\n",
       "B          506  356.67403162055257    91.29486438415782     0.32    396.9\n",
       "LSTAT      506  12.653063241106723    7.141061511348571     1.73    37.97\n",
       "MV         506  22.532806324110698    9.197104087379815      5.0     50.0"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df.describe().toPandas().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('CRIM', 'double'),\n",
       " ('ZN', 'double'),\n",
       " ('INDUS', 'double'),\n",
       " ('CHAS', 'int'),\n",
       " ('NOX', 'double'),\n",
       " ('RM', 'double'),\n",
       " ('AGE', 'double'),\n",
       " ('DIS', 'double'),\n",
       " ('RAD', 'int'),\n",
       " ('TAX', 'int'),\n",
       " ('PT', 'double'),\n",
       " ('B', 'double'),\n",
       " ('LSTAT', 'double'),\n",
       " ('MV', 'double')]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correlation between CRIM and MV : -0.38830460858681154\n",
      "correlation between ZN and MV : 0.3604453424505433\n",
      "correlation between INDUS and MV : -0.4837251600283728\n",
      "correlation between CHAS and MV : 0.1752601771902987\n",
      "correlation between NOX and MV : -0.4273207723732821\n",
      "correlation between RM and MV : 0.6953599470715401\n",
      "correlation between AGE and MV : -0.3769545650045961\n",
      "correlation between DIS and MV : 0.249928734085904\n",
      "correlation between RAD and MV : -0.38162623063977735\n",
      "correlation between TAX and MV : -0.46853593356776674\n",
      "correlation between PT and MV : -0.5077866855375622\n",
      "correlation between B and MV : 0.3334608196570661\n",
      "correlation between LSTAT and MV : -0.7376627261740145\n"
     ]
    }
   ],
   "source": [
    "for i in columns[:-1]:\n",
    "    print(f\"correlation between {i} and MV : {housing_df.stat.corr('MV',i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+\n",
      "|  MV|            features|\n",
      "+----+--------------------+\n",
      "|24.0|[0.00632,18.0,2.3...|\n",
      "|21.6|[0.02731,0.0,7.07...|\n",
      "|34.7|[0.02729,0.0,7.07...|\n",
      "+----+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "vectorAssembler = VectorAssembler(inputCols=columns[:-1],outputCol='features')\n",
    "\n",
    "vector_df = vectorAssembler.transform(housing_df)\n",
    "vector_df = vector_df.select(['MV','features'])\n",
    "vector_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "### train test split\n",
    "\n",
    "train_df,test_df = vector_df.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of training set : 335\n",
      "Length of test set : 171\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length of training set : {train_df.count()}\")\n",
    "print(f\"Length of test set : {test_df.count()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` we will benchmark three regression algorithm - linear, decision tree, gradient boost ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression, DecisionTreeRegressor, GBTRegressor\n",
    "\n",
    "lr = LinearRegression(featuresCol='features',labelCol='MV',regParam=0.3,maxIter=10,elasticNetParam=0.8)\n",
    "dtr = DecisionTreeRegressor(featuresCol='features',labelCol='MV')\n",
    "gbt = GBTRegressor(featuresCol='features',labelCol='MV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/04/18 18:36:41 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n"
     ]
    }
   ],
   "source": [
    "lr_model = lr.fit(train_df)\n",
    "dtr_model = dtr.fit(train_df)\n",
    "gbt_model = gbt.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficients for linear model : [0.0,0.009632288565546298,-0.041930335329341234,2.189511753983001,-5.917148486856851,3.691408547245096,0.0,-0.807420428565707,0.0020999178638041655,0.0,-0.6951831667681138,0.009144862148678993,-0.5747695143913841]\n",
      "intercept for linear model : 22.93522628182439\n"
     ]
    }
   ],
   "source": [
    "print(f\"coefficients for linear model : {lr_model.coefficients}\")\n",
    "print(f\"intercept for linear model : {lr_model.intercept}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions\n",
    "\n",
    "lr_predictions = lr_model.transform(test_df)\n",
    "dtr_predictions = dtr_model.transform(test_df)\n",
    "gbt_predictions = gbt_model.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+------------------+\n",
      "| MV|            features|        prediction|\n",
      "+---+--------------------+------------------+\n",
      "|5.6|[25.0461,0.0,18.1...|13.144050652991455|\n",
      "|7.5|[10.8342,0.0,18.1...|13.106221647837062|\n",
      "|8.3|[15.8603,0.0,18.1...|10.440540279266923|\n",
      "|8.3|[24.8017,0.0,18.1...|14.720272671732284|\n",
      "|8.4|[13.6781,0.0,18.1...| 5.320694853314091|\n",
      "+---+--------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+-----------------+\n",
      "| MV|            features|       prediction|\n",
      "+---+--------------------+-----------------+\n",
      "|5.6|[25.0461,0.0,18.1...|9.976666666666672|\n",
      "|7.5|[10.8342,0.0,18.1...|9.976666666666672|\n",
      "|8.3|[15.8603,0.0,18.1...|9.976666666666672|\n",
      "|8.3|[24.8017,0.0,18.1...|9.976666666666672|\n",
      "|8.4|[13.6781,0.0,18.1...|9.976666666666672|\n",
      "+---+--------------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtr_predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Squared (R2) on test data = 0.759503\n",
      "rmse on test data = 4.51484\n",
      "R Squared (R2) on test data = 0.848625\n",
      "rmse on test data = 3.58191\n",
      "R Squared (R2) on test data = 0.875717\n",
      "rmse on test data = 3.24559\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "evaluator_r2 = RegressionEvaluator(predictionCol=\"prediction\",labelCol=\"MV\",metricName=\"r2\")\n",
    "evaluator_rmse = RegressionEvaluator(predictionCol=\"prediction\",labelCol=\"MV\",metricName=\"rmse\")\n",
    "print(\"R Squared (R2) on test data = %g\" % evaluator_r2.evaluate(lr_predictions))\n",
    "print(\"rmse on test data = %g\" % evaluator_rmse.evaluate(lr_predictions))\n",
    "print(\"R Squared (R2) on test data = %g\" % evaluator_r2.evaluate(dtr_predictions))\n",
    "print(\"rmse on test data = %g\" % evaluator_rmse.evaluate(dtr_predictions))\n",
    "print(\"R Squared (R2) on test data = %g\" % evaluator_r2.evaluate(gbt_predictions))\n",
    "print(\"rmse on test data = %g\" % evaluator_rmse.evaluate(gbt_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSummary = lr_model.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|          residuals|\n",
      "+-------------------+\n",
      "| -4.057315050301204|\n",
      "|  -9.22307320676619|\n",
      "| -4.040654816332746|\n",
      "|  -5.14075798748101|\n",
      "|  8.021747618989632|\n",
      "|-10.977324543935051|\n",
      "|-1.0910290106258875|\n",
      "|-2.7875328829701553|\n",
      "| 0.8842440894994557|\n",
      "| 0.7146681044082417|\n",
      "|-6.6499421502125795|\n",
      "|-1.9784114283907108|\n",
      "| -4.199191696804837|\n",
      "|-3.3430892168468613|\n",
      "|  2.131922991801815|\n",
      "| -4.146704641094182|\n",
      "| 3.0951194396061474|\n",
      "|-1.6100103599175277|\n",
      "| -6.482666700117187|\n",
      "|-2.9798341672991455|\n",
      "+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainingSummary.residuals.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ```spark structured streaming```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```diff\n",
    "-spark.read -> spark.readStream\n",
    "+DataFrameReader -> DataStreamReader\n",
    "#write (to parquet,csv,etc) -> writeStream (console, parquet,csv using output mode complete,append,update) \n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```Example 1```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "cities = spark.read.csv('/home/snehil/snehi/Desktop/Data/cities.csv',header=True)\n",
    "cities = cities.select(['name']).rdd.map(lambda x:x[0]).takeSample(False,15)\n",
    "\n",
    "names = spark.read.csv('/home/snehil/snehi/Desktop/Data/name.csv',header=True)\n",
    "names = names.select(['name']).rdd.map(lambda x:x[0]).collect()\n",
    "\n",
    "profession = ['Doctor','Engineer','Lawyer','Clerk','Cook','Manager','Developer','Designer']\n",
    "\n",
    "result_list = []\n",
    "count = 0\n",
    "for i in range(2000):\n",
    "    result_list.append([count, random.choice(names),random.randint(25,75),random.choice(profession),random.choice(cities),random.randint(5000,100000)])\n",
    "    count+=1\n",
    "\n",
    "result_df = spark.createDataFrame(result_list, ['id','name','age','profession','city','salary'])\n",
    "result_df.repartition(10).write.mode('overwrite').parquet('data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = result_df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer = spark.readStream.format('parquet').schema(schema).option('maxFilesPerTrigger',1).load('streamdata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer.isStreaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer.createOrReplaceTempView('customer_db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_salaries = spark.sql(\"\"\"\n",
    "    select profession,count(*) as count, avg(salary) as avg_salary from customer_db group by profession order by avg_salary;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/04/18 19:35:00 WARN ResolveWriteToStream: Temporary checkpoint location created which is deleted normally when the query didn't fail: /tmp/temporary-a3cbb73a-dfbe-4fe6-9010-308cf256fb00. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.\n",
      "23/04/18 19:35:00 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 0\n",
      "-------------------------------------------\n",
      "+----------+-----+------------------+\n",
      "|profession|count|        avg_salary|\n",
      "+----------+-----+------------------+\n",
      "|    Lawyer|   32|       48341.09375|\n",
      "|  Designer|   26| 49607.92307692308|\n",
      "|   Manager|   27|           51095.0|\n",
      "| Developer|   19| 53043.68421052631|\n",
      "|      Cook|   28| 53107.46428571428|\n",
      "|     Clerk|   28| 54161.67857142857|\n",
      "|    Doctor|   23|55497.608695652176|\n",
      "|  Engineer|   17| 66600.88235294117|\n",
      "+----------+-----+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 1\n",
      "-------------------------------------------\n",
      "+----------+-----+------------------+\n",
      "|profession|count|        avg_salary|\n",
      "+----------+-----+------------------+\n",
      "|    Lawyer|   56| 51075.08928571428|\n",
      "|   Manager|   49| 51105.32653061225|\n",
      "|      Cook|   48|52422.104166666664|\n",
      "|    Doctor|   54| 53069.48148148148|\n",
      "|     Clerk|   60| 53949.48333333333|\n",
      "| Developer|   47| 54864.44680851064|\n",
      "|  Designer|   50|          55012.84|\n",
      "|  Engineer|   36| 58323.27777777778|\n",
      "+----------+-----+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 2\n",
      "-------------------------------------------\n",
      "+----------+-----+------------------+\n",
      "|profession|count|        avg_salary|\n",
      "+----------+-----+------------------+\n",
      "|   Manager|   70|49454.385714285716|\n",
      "|      Cook|   73|50718.068493150684|\n",
      "|    Doctor|   71| 51698.94366197183|\n",
      "|    Lawyer|   89|  51743.5393258427|\n",
      "|     Clerk|   86| 52963.61627906977|\n",
      "|  Engineer|   60|           54306.6|\n",
      "|  Designer|   79| 54838.36708860759|\n",
      "| Developer|   72|55814.430555555555|\n",
      "+----------+-----+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 3\n",
      "-------------------------------------------\n",
      "+----------+-----+-----------------+\n",
      "|profession|count|       avg_salary|\n",
      "+----------+-----+-----------------+\n",
      "|    Lawyer|  118|49580.70338983051|\n",
      "|      Cook|   91|50684.37362637363|\n",
      "|   Manager|   95|50718.31578947369|\n",
      "|     Clerk|  112|       51699.9375|\n",
      "|  Engineer|   81|52181.30864197531|\n",
      "|    Doctor|   97|52514.45360824742|\n",
      "| Developer|  103|53614.63106796116|\n",
      "|  Designer|  103|54780.65048543689|\n",
      "+----------+-----+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 4\n",
      "-------------------------------------------\n",
      "+----------+-----+------------------+\n",
      "|profession|count|        avg_salary|\n",
      "+----------+-----+------------------+\n",
      "|   Manager|  116| 49610.18965517241|\n",
      "|    Lawyer|  148| 50611.82432432433|\n",
      "|     Clerk|  131| 51181.85496183206|\n",
      "|    Doctor|  123| 51571.86178861788|\n",
      "|  Engineer|  104|52062.028846153844|\n",
      "|      Cook|  111| 52270.81081081081|\n",
      "|  Designer|  132| 54704.97727272727|\n",
      "| Developer|  135|57053.474074074074|\n",
      "+----------+-----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = average_salaries.writeStream.format(\"console\").outputMode(\"complete\").start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "query.stop()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```Example 2 - count frequency of words in files```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### streaming lines of files added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = spark.readStream.text('textdata/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_lines = lines.select(lines.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/04/19 14:59:06 WARN ResolveWriteToStream: Temporary checkpoint location created which is deleted normally when the query didn't fail: /tmp/temporary-5cdff81e-2b4b-4100-ae8a-a9deb9aeaa0d. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.\n",
      "23/04/19 14:59:06 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 0\n",
      "-------------------------------------------\n",
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|\"At the end of my...|\n",
      "|\"I've looked in t...|\n",
      "|I've gazed and I'...|\n",
      "|I've glanced at t...|\n",
      "|And *that's* how ...|\n",
      "|                    |\n",
      "|\"My penis, my *pe...|\n",
      "|It ends in a hole...|\n",
      "|It leads to a pla...|\n",
      "|to a space in the...|\n",
      "|And when you can ...|\n",
      "|                    |\n",
      "|\"Remember the hol...|\n",
      "|He turned to the ...|\n",
      "|\"A hole in my pen...|\n",
      "|                    |\n",
      "|The other was fro...|\n",
      "|                    |\n",
      "|\"... just *one*?\"...|\n",
      "|  In the darkness,  |\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1\n",
      "-------------------------------------------\n",
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|>It still fucks w...|\n",
      "|                    |\n",
      "|You've lots of fr...|\n",
      "|       and dreams,  |\n",
      "|Your own contente...|\n",
      "|         it seems,  |\n",
      "|A strength of wil...|\n",
      "|          you see,  |\n",
      "|You stand alone i...|\n",
      "|                    |\n",
      "|You've luck and l...|\n",
      "|         to share,  |\n",
      "|And though it hel...|\n",
      "|         and care,  |\n",
      "|You know denied i...|\n",
      "|       your heart,  |\n",
      "|In certain things...|\n",
      "|                    |\n",
      "|But when you fear...|\n",
      "| You have to know:  |\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = output_lines.writeStream.format(\"console\").outputMode(\"update\").start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "query.stop()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### streaming wordcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode,split,desc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = spark.readStream.text(\"textdata/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_count = lines.select(explode(split(lines.value,' '))).groupBy('col').count().sort(desc(\"count\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/04/19 15:02:01 WARN ResolveWriteToStream: Temporary checkpoint location created which is deleted normally when the query didn't fail: /tmp/temporary-38a570cf-090e-45f8-a86f-419fee66b2ef. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.\n",
      "23/04/19 15:02:01 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 0\n",
      "-------------------------------------------\n",
      "+----+-----+\n",
      "| col|count|\n",
      "+----+-----+\n",
      "|    |  118|\n",
      "| and|   13|\n",
      "| the|   11|\n",
      "|  he|   11|\n",
      "|  in|    9|\n",
      "|   -|    9|\n",
      "|   a|    8|\n",
      "|  to|    8|\n",
      "| you|    6|\n",
      "|  my|    6|\n",
      "|   I|    5|\n",
      "|  In|    4|\n",
      "|when|    4|\n",
      "|I've|    4|\n",
      "|  of|    4|\n",
      "| can|    3|\n",
      "| was|    3|\n",
      "|hole|    3|\n",
      "|  it|    3|\n",
      "| You|    3|\n",
      "+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 2\n",
      "-------------------------------------------\n",
      "+--------------------+-----+\n",
      "|                 col|count|\n",
      "+--------------------+-----+\n",
      "|                    |63801|\n",
      "|                 and| 5662|\n",
      "|                 the| 4886|\n",
      "|                   -| 4482|\n",
      "|_________________...| 4458|\n",
      "|                   a| 3612|\n",
      "|                   I| 3177|\n",
      "|                  to| 3174|\n",
      "|                 And| 2360|\n",
      "|               Link:| 2229|\n",
      "|                   || 2229|\n",
      "|               Date:| 2229|\n",
      "|          Subreddit:| 2229|\n",
      "|                  of| 2161|\n",
      "|           AskReddit| 2090|\n",
      "|                  in| 1517|\n",
      "|                 you| 1483|\n",
      "|                  it| 1452|\n",
      "|                  he| 1347|\n",
      "|                with| 1285|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 1\n",
      "-------------------------------------------\n",
      "+--------------------+-----+\n",
      "|                 col|count|\n",
      "+--------------------+-----+\n",
      "|                    |63801|\n",
      "|                 and| 5662|\n",
      "|                 the| 4886|\n",
      "|                   -| 4482|\n",
      "|_________________...| 4458|\n",
      "|                   a| 3612|\n",
      "|                   I| 3177|\n",
      "|                  to| 3174|\n",
      "|                 And| 2360|\n",
      "|               Link:| 2229|\n",
      "|                   || 2229|\n",
      "|               Date:| 2229|\n",
      "|          Subreddit:| 2229|\n",
      "|                  of| 2161|\n",
      "|           AskReddit| 2090|\n",
      "|                  in| 1517|\n",
      "|                 you| 1483|\n",
      "|                  it| 1452|\n",
      "|                  he| 1347|\n",
      "|                with| 1285|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 1\n",
      "-------------------------------------------\n",
      "+--------------------+------+\n",
      "|                 col| count|\n",
      "+--------------------+------+\n",
      "|                    |127484|\n",
      "|                 and| 11311|\n",
      "|                 the|  9761|\n",
      "|                   -|  8955|\n",
      "|_________________...|  8916|\n",
      "|                   a|  7216|\n",
      "|                   I|  6349|\n",
      "|                  to|  6340|\n",
      "|                 And|  4717|\n",
      "|               Link:|  4458|\n",
      "|                   ||  4458|\n",
      "|               Date:|  4458|\n",
      "|          Subreddit:|  4458|\n",
      "|                  of|  4318|\n",
      "|           AskReddit|  4180|\n",
      "|                  in|  3025|\n",
      "|                 you|  2960|\n",
      "|                  it|  2901|\n",
      "|                  he|  2683|\n",
      "|                with|  2568|\n",
      "+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = words_count.writeStream.format(\"console\").outputMode(\"complete\").start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "query.stop()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```Example 3 - using streams```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/04/19 18:42:35 WARN TextSocketSourceProvider: The socket source should not be used for production applications! It does not support recovery.\n"
     ]
    }
   ],
   "source": [
    "# run nc -lk 65432 on cli to start a netcat server\n",
    "lines = spark.readStream.format(\"socket\").option(\"host\", \"localhost\").option(\"port\", 65431).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment this if want stream from multiple sources\n",
    "#lines1 = spark.readStream.format(\"socket\").option(\"host\", \"localhost\").option(\"port\", 65432).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_count = lines.select(explode(split(lines.value,' '))).groupBy('col').count().sort(desc(\"count\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment this if want stream from multiple sources\n",
    "# words_count1 = lines1.select(explode(split(lines1.value,' '))).groupBy('col').count().sort(desc(\"count\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment this if want stream from multiple sources\n",
    "#words_count = words_count.union(words_count1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/04/19 18:44:20 WARN ResolveWriteToStream: Temporary checkpoint location created which is deleted normally when the query didn't fail: /tmp/temporary-f6e2505b-42b7-4e24-b838-a3f3f7dc5af7. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.\n",
      "23/04/19 18:44:20 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 0\n",
      "-------------------------------------------\n",
      "+---+-----+\n",
      "|col|count|\n",
      "+---+-----+\n",
      "+---+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 1\n",
      "-------------------------------------------\n",
      "+----+-----+\n",
      "| col|count|\n",
      "+----+-----+\n",
      "|loal|    1|\n",
      "+----+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 2\n",
      "-------------------------------------------\n",
      "+----+-----+\n",
      "| col|count|\n",
      "+----+-----+\n",
      "|goal|    1|\n",
      "|loal|    1|\n",
      "+----+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 3\n",
      "-------------------------------------------\n",
      "+----+-----+\n",
      "| col|count|\n",
      "+----+-----+\n",
      "|goal|    1|\n",
      "|koal|    1|\n",
      "|loal|    1|\n",
      "+----+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 4\n",
      "-------------------------------------------\n",
      "+----+-----+\n",
      "| col|count|\n",
      "+----+-----+\n",
      "|koal|    2|\n",
      "|goal|    1|\n",
      "|loal|    1|\n",
      "+----+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 5\n",
      "-------------------------------------------\n",
      "+------+-----+\n",
      "|   col|count|\n",
      "+------+-----+\n",
      "|  koal|    2|\n",
      "| koala|    1|\n",
      "|    is|    1|\n",
      "|animal|    1|\n",
      "|  goal|    1|\n",
      "|    an|    1|\n",
      "|  loal|    1|\n",
      "+------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 6\n",
      "-------------------------------------------\n",
      "+------+-----+\n",
      "|   col|count|\n",
      "+------+-----+\n",
      "| koala|    1|\n",
      "|    is|    1|\n",
      "|animal|    1|\n",
      "|  goal|    1|\n",
      "|    an|    1|\n",
      "|  koal|    2|\n",
      "|    in|    1|\n",
      "|jungle|    1|\n",
      "|  loal|    1|\n",
      "|living|    1|\n",
      "+------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/04/19 18:45:30 WARN TextSocketMicroBatchStream: Stream closed by localhost:65432\n",
      "ERROR:root:KeyboardInterrupt while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/snehil/.venv/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/snehil/.venv/lib/python3.8/site-packages/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/usr/lib/python3.8/socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m query \u001b[39m=\u001b[39m words_count\u001b[39m.\u001b[39mwriteStream\u001b[39m.\u001b[39mformat(\u001b[39m\"\u001b[39m\u001b[39mconsole\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39moutputMode(\u001b[39m\"\u001b[39m\u001b[39mcomplete\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mstart()\n\u001b[0;32m----> 2\u001b[0m query\u001b[39m.\u001b[39;49mawaitTermination()\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/pyspark/sql/streaming/query.py:201\u001b[0m, in \u001b[0;36mStreamingQuery.awaitTermination\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jsq\u001b[39m.\u001b[39mawaitTermination(\u001b[39mint\u001b[39m(timeout \u001b[39m*\u001b[39m \u001b[39m1000\u001b[39m))\n\u001b[1;32m    200\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jsq\u001b[39m.\u001b[39;49mawaitTermination()\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1314\u001b[0m args_command, temp_args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_args(\u001b[39m*\u001b[39margs)\n\u001b[1;32m   1316\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1321\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client\u001b[39m.\u001b[39;49msend_command(command)\n\u001b[1;32m   1322\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_id, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname)\n\u001b[1;32m   1325\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49msend_command(command)\n\u001b[1;32m   1039\u001b[0m     \u001b[39mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[39mreturn\u001b[39;00m response, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/py4j/clientserver.py:511\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         answer \u001b[39m=\u001b[39m smart_decode(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstream\u001b[39m.\u001b[39;49mreadline()[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[1;32m    512\u001b[0m         logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mAnswer received: \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(answer))\n\u001b[1;32m    513\u001b[0m         \u001b[39m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    514\u001b[0m         \u001b[39m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.8/socket.py:669\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    668\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 669\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    670\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    671\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "query = words_count.writeStream.format(\"console\").outputMode(\"complete\").start()\n",
    "query.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
